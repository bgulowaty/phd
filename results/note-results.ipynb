{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33b02f1-b889-4266-b80c-9a75dbfe77d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run load_base_runs.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:36.221597Z",
     "start_time": "2024-07-17T21:41:35.868711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72cf036e9eec1f2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:37.442048Z",
     "start_time": "2024-07-17T21:41:36.392915Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import scienceplots\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_blobs\n",
    "from cycler import cycler\n",
    "from pathlib import Path\n",
    "plt.style.use(['science', 'bright'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d808c1b-e77a-46bc-9d3c-923bef5ce3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTE_PARAMS = ['metrics.no_of_predicates_median', 'metrics.complex_clfs',\n",
    "                     'metrics.rules', 'metrics.no_of_predicates_max',\n",
    "                     'metrics.dummy_clfs', 'metrics.no_of_predicates_min',\n",
    "                     'metrics.all_clfs', 'params.min_split_percentage',\n",
    "                    'params.complexity_measure',\n",
    "                     'params.base_clf','params.min_samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a860c30-ff3b-4975-96cf-72f923d087e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTE_PARAMS = ['cls_data', 'params.subspaces', 'params.n_clf', \"params.cv\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e40f3906-be22-4993-a64a-dbd827d8da9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['cls_data'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     note_runs \u001b[38;5;241m=\u001b[39m load_cache(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m24.07-note\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m     note_runs \u001b[38;5;241m=\u001b[39m \u001b[43mget_runs_for\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m24.07-note\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_report\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43martifact_uri\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcls_report\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mDATASET_PARAMS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcls_report\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mNOTE_PARAMS\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/results-eOh1dAZ8-py3.8/lib/python3.8/site-packages/pandas/core/frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/results-eOh1dAZ8-py3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5877\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/results-eOh1dAZ8-py3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['cls_data'] not in index\""
     ]
    }
   ],
   "source": [
    "if cached(\"24.07-note\"):\n",
    "    note_runs = load_cache(\"24.07-note\")\n",
    "else:\n",
    "    note_runs = get_runs_for(\"24.07-note\")\\\n",
    "        .assign(cls_report=lambda row: row['artifact_uri'].apply(lambda v: get_metrics(v, \"cls_report\")))\\\n",
    "        [DATASET_PARAMS + ['cls_report'] + NOTE_PARAMS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaa92a2-0eec-4366-bf8b-b14fd1846965",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache(note_runs, \"24.07-note\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071b62ba-3193-4c58-85ba-5beab3f47d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_runs_exploded = note_runs.explode('cls_report').rename(columns={\"cls_report\": \"metric\"}).assign(cls_report=note_runs['cls_report'].apply(lambda it: it.values()).explode()).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd0b54c-f410-4136-9f0d-912933d113b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_runs_exploded = note_runs_exploded.assign(complexity_dts=lambda row: row['cls_report'].apply(calculate_rf_compexity))\\\n",
    "    .assign(complexity_rules=lambda row: row['cls_report'].apply(lambda it: sum(it['rules'])))\\\n",
    "    .assign(complexity=lambda row: row['complexity_dts'] + row['complexity_rules'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cd86c7-9440-4290-87c9-859d67261a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_runs_exploded['imb_cls_report'] = note_runs_exploded['cls_report']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d34aea-7542-4737-9962-95c26a333249",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_runs_exploded = note_runs_exploded\\\n",
    "    .assign(**classification_metrics_extractors)\\\n",
    "    .assign(complexity_dts=lambda row: row['cls_report'].apply(calculate_rf_compexity))\\\n",
    "    .assign(complexity_rules=lambda row: row['cls_report'].apply(lambda it: sum(it['rules'])))\\\n",
    "    .assign(complexity=lambda row: row['complexity_dts'] + row['complexity_rules'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99b41ec-b931-457f-a253-2c7760c2534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_runs_exploded.groupby('metric')['test_balanced_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d326705b5f96e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:37.520329Z",
     "start_time": "2024-07-17T21:41:37.506662Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "DATASET_PARAMS = ['params.should_take_test', 'params.dataset', 'params.data_shuffle_random_state']\n",
    "RF_METRICS = ['metrics.depth_mean',\n",
    "              'metrics.depth_min',\n",
    "              'metrics.depth_median',\n",
    "              'metrics.n_leaves_max',\n",
    "              'metrics.n_leaves_min',\n",
    "              'metrics.n_leaves_mean',\n",
    "              'metrics.depth_max',\n",
    "              'metrics.n_leaves_median',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c463dd1a0058ecd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:37.532753Z",
     "start_time": "2024-07-17T21:41:37.521200Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(row):\n",
    "    return (row['metrics.tp'] + row['metrics.tn']) / (row['metrics.fp'] + row['metrics.tp'] + row['metrics.tn'] + row['metrics.fn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dbd8a64c58dd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:37.545851Z",
     "start_time": "2024-07-17T21:41:37.533376Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_recall(row):\n",
    "    return row['metrics.tp'] / (row['metrics.tp'] + row['metrics.fn'])\n",
    "\n",
    "def calculate_precision(row):\n",
    "    return row['metrics.tp'] / (row['metrics.tp'] + row['metrics.fp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec18df8500f804b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:38.206707Z",
     "start_time": "2024-07-17T21:41:37.546703Z"
    }
   },
   "outputs": [],
   "source": [
    "base_runs_dt = get_runs_for(\"base_runs_dt\")[CLASSIFICATION_METRICS + DATASET_PARAMS + ['metrics.depth', \"metrics.n_leaves\"]]\\\n",
    "    .assign(test_accuracy=calculate_accuracy) \\\n",
    "    .assign(test_recall=calculate_recall)\\\n",
    "    .assign(test_precision=calculate_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97659709-b137-46bf-a60a-62aff7849d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_dt.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e05f45a53e2433",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:39.072205Z",
     "start_time": "2024-07-17T21:41:38.212090Z"
    }
   },
   "outputs": [],
   "source": [
    "base_runs_rf = get_runs_for(\"base_runs_rf_extended\")\\\n",
    "    .assign(complex_dt_metrics=lambda row: row['artifact_uri'].apply(lambda v: get_metrics(v, \"complex_dt.json\")))\\\n",
    "    [CLASSIFICATION_METRICS + DATASET_PARAMS + RF_METRICS]\\\n",
    "    .assign(test_accuracy=calculate_accuracy) \\\n",
    "    .assign(test_recall=calculate_recall) \\\n",
    "    .assign(test_precision=calculate_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7071f8af-15ca-4da4-b175-1b7b5e064a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_runs_rf['complex_dt_metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eedb862bc4dc5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:39.633512Z",
     "start_time": "2024-07-17T21:41:39.073005Z"
    }
   },
   "outputs": [],
   "source": [
    "base_runs_oner = (get_runs_for(\"base_runs_oner\")[CLASSIFICATION_METRICS + DATASET_PARAMS + ['metrics.rules_no', 'metrics.depth']]\n",
    "\n",
    "    .assign(test_accuracy=calculate_accuracy)) \\\n",
    "    .assign(test_recall=calculate_recall) \\\n",
    "    .assign(test_precision=calculate_precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce55cd251fa361f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:40.227288Z",
     "start_time": "2024-07-17T21:41:39.634326Z"
    }
   },
   "outputs": [],
   "source": [
    "base_runs_rulefit = (get_runs_for(\"base_runs_rulefit\")[CLASSIFICATION_METRICS + DATASET_PARAMS + ['metrics.max_rules', 'metrics.rules_no', 'metrics.terms_no']]\n",
    "    .assign(test_accuracy=calculate_accuracy)) \\\n",
    "    .assign(test_recall=calculate_recall) \\\n",
    "    .assign(test_precision=calculate_precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f51c801058f0c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:41.039301Z",
     "start_time": "2024-07-17T21:41:40.228124Z"
    }
   },
   "outputs": [],
   "source": [
    "base_runs_greedy = (get_runs_for(\"base_runs_greedy\")[CLASSIFICATION_METRICS + DATASET_PARAMS + ['metrics.depth', 'metrics.rules_no']]\n",
    "        .assign(test_accuracy=calculate_accuracy))\\\n",
    "    .assign(test_recall=calculate_recall) \\\n",
    "    .assign(test_precision=calculate_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebeebf79ec555e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:52.602211Z",
     "start_time": "2024-07-17T21:41:41.040221Z"
    }
   },
   "outputs": [],
   "source": [
    "quad_split_runs_df =get_runs_for(\"06.07-quadsplit-3\")[CLASSIFICATION_METRICS + DATASET_PARAMS + QUAD_SPLIT_PARAMS] \\\n",
    "    .assign(test_accuracy=calculate_accuracy) \\\n",
    "    .assign(test_recall=calculate_recall) \\\n",
    "    .assign(test_precision=calculate_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef439416fbfd393",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:52.647559Z",
     "start_time": "2024-07-17T21:41:52.632453Z"
    }
   },
   "outputs": [],
   "source": [
    "base_runs_rf.rename(columns={c: c+'_rf' for c in base_runs_rf.columns if 'metric' in c or 'test_' in c}, inplace=True)\n",
    "base_runs_dt.rename(columns={c: c+'_dt' for c in base_runs_dt.columns if 'metric' in c  or 'test_' in c}, inplace=True)\n",
    "base_runs_greedy.rename(columns={c: c+'_greedy' for c in base_runs_greedy.columns if 'metric' in c or 'test_' in c}, inplace=True)\n",
    "base_runs_oner.rename(columns={c: c+'_oner' for c in base_runs_oner.columns if 'metric' in c or 'test_' in c}, inplace=True)\n",
    "base_runs_rulefit.rename(columns={c: c+'_rulefit' for c in base_runs_rulefit.columns if 'metric' in c or 'test_' in c}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9b32953ecb9b33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:52.672808Z",
     "start_time": "2024-07-17T21:41:52.648194Z"
    }
   },
   "outputs": [],
   "source": [
    "base_runs_together_df = pd.merge(\n",
    "    base_runs_dt,\n",
    "    base_runs_rf,\n",
    "    how='right',\n",
    "    on=DATASET_PARAMS,\n",
    "    suffixes=('_dt', '_rf')\n",
    ")\\\n",
    "    .merge(base_runs_greedy, how='right', on=DATASET_PARAMS, suffixes=('', '_greedy'))\\\n",
    "    .merge(base_runs_oner, how='right', on=DATASET_PARAMS, suffixes=('', '_oner'))\\\n",
    "    .merge(base_runs_rulefit, how='right', on=DATASET_PARAMS, suffixes=('', '_rulefit'))\\\n",
    "    .dropna()\n",
    "note_runs_df = pd.merge(\n",
    "    base_runs_together_df,\n",
    "    note_runs,\n",
    "    how='right',\n",
    "    on=DATASET_PARAMS,\n",
    "    suffixes=('', '_opt')\n",
    ")\n",
    "note_runs_df = pd.merge(\n",
    "    note_runs_df,\n",
    "    complexities_df,\n",
    "    how='left',\n",
    "    on=DATASET_PARAMS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b95eb8-d9cf-4681-aad3-afb9b5f756d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_runs_df[['test_accuracy_rf', 'test_accuracy_dt', 'test_accuracy', 'test_accuracy_by_acc']].mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32c81ec-42df-4611-8b29-f9de579c5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_THAT_SHOULD_BE =[\"better\", \"equal\", \"worse\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5702225cd8ffe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:52.704752Z",
     "start_time": "2024-07-17T21:41:52.688086Z"
    }
   },
   "outputs": [],
   "source": [
    "quad_split_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e6820e528f789f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:52.717938Z",
     "start_time": "2024-07-17T21:41:52.705530Z"
    }
   },
   "outputs": [],
   "source": [
    "LIMITING_QUERY = \"`params.min_samples` == '28' and `params.min_split_percentage` == '0.183'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23fa32c39aed24b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:52.736523Z",
     "start_time": "2024-07-17T21:41:52.718818Z"
    }
   },
   "outputs": [],
   "source": [
    "quad_split_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2e3ff5c84c2327",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:52.749454Z",
     "start_time": "2024-07-17T21:41:52.737256Z"
    }
   },
   "outputs": [],
   "source": [
    "METRICS = ['test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99eeeee3f3af329",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:52.761563Z",
     "start_time": "2024-07-17T21:41:52.750417Z"
    }
   },
   "outputs": [],
   "source": [
    "SUFFIXES = [\"_dt\", \"_rf\", \"_oner\", \"_rulefit\", \"_greedy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f711d4da9789c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:52.775175Z",
     "start_time": "2024-07-17T21:41:52.762390Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_comparison(row, suffix, metric):\n",
    "    if row[f'{metric}_equal{suffix}']:\n",
    "        return \"equal\"\n",
    "    if row[f'{metric}_better{suffix}']:\n",
    "        return \"better\"\n",
    "    else:\n",
    "        return \"worse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d69acd8b5b4e47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:53.091533Z",
     "start_time": "2024-07-17T21:41:52.776343Z"
    }
   },
   "outputs": [],
   "source": [
    "for suffix in SUFFIXES:\n",
    "    for metric in METRICS:\n",
    "        note_runs_df[f'{metric}_diff_to{suffix}'] = note_runs_df[metric] - note_runs_df[f'{metric}{suffix}']\n",
    "        note_runs_df[f'{metric}_better_equal{suffix}'] = note_runs_df[metric] >= note_runs_df[f'{metric}{suffix}']\n",
    "        note_runs_df[f'{metric}_better{suffix}'] = note_runs_df[metric] > note_runs_df[f'{metric}{suffix}']\n",
    "        note_runs_df[f'{metric}_worse{suffix}'] = ~note_runs_df[f'{metric}_better_equal{suffix}']\n",
    "        note_runs_df[f'{metric}_worse_equal{suffix}'] = ~note_runs_df[f'{metric}_better{suffix}']\n",
    "        note_runs_df[f'{metric}_equal{suffix}'] = note_runs_df[metric] == quad_split_df[f'{metric}{suffix}']\n",
    "        note_runs_df[f'{metric}_comparison{suffix}'] = note_runs_df.apply(lambda row: define_comparison(row, suffix, metric), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17a952891ffa4df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:53.129453Z",
     "start_time": "2024-07-17T21:41:53.108663Z"
    }
   },
   "outputs": [],
   "source": [
    "# note_runs_df['complexity_rf'] = note_runs_df['metrics.depth_median_rf'] * 32 * note_runs_df['metrics.n_leaves_median_rf']\n",
    "# note_runs_df['complexity'] =  note_runs_df['metrics.rules']\n",
    "# note_runs_df['complexity_dt'] = note_runs_df['metrics.depth_dt'] * note_runs_df['metrics.n_leaves_dt']\n",
    "# note_runs_df['complexity_rulefit'] = note_runs_df['metrics.rules_no_rulefit']\n",
    "# note_runs_df['complexity_oner'] = note_runs_df['metrics.rules_no_oner']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c198c9330c7c06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:53.179919Z",
     "start_time": "2024-07-17T21:41:53.137611Z"
    }
   },
   "outputs": [],
   "source": [
    "# for metric in COMPLEXITY_METRICS:\n",
    "#     quad_split_df[f'{metric}-discretized'] = pd.qcut(quad_split_df[metric], 3, labels=[\"low\", \"medium\", \"high\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558bece3173d68a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:53.194840Z",
     "start_time": "2024-07-17T21:41:53.180950Z"
    }
   },
   "outputs": [],
   "source": [
    "ALL_DISCRETIZED_METRICS = [f'{metric}-discretized' for metric in COMPLEXITY_METRICS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a7907a75c68cf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:53.211364Z",
     "start_time": "2024-07-17T21:41:53.195664Z"
    }
   },
   "outputs": [],
   "source": [
    "# compare_values = {\n",
    "#     \"low\": 0,\n",
    "#     \"medium\": 1,\n",
    "#     \"high\": 2,\n",
    "# }\n",
    "# compare_values_inverted = {\n",
    "#     v: k for k, v in compare_values.items()\n",
    "# }\n",
    "# def take_higher(row):\n",
    "#     vals = [compare_values[it] for it in [row[0], row[1]]]\n",
    "#     max_val = max(vals)\n",
    "    \n",
    "#     return compare_values_inverted[max_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b892797265e1e4b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:54.440510Z",
     "start_time": "2024-07-17T21:41:53.212385Z"
    }
   },
   "outputs": [],
   "source": [
    "# quad_split_df['overall-complexity'] = quad_split_df[ALL_DISCRETIZED_METRICS].mode(axis=1).fillna('low').apply(take_higher, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b03f1391512aad7",
   "metadata": {},
   "source": [
    "# COMPARISON TO ALGORITHSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdf6574-bf28-4ce4-b044-5970c488ca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [f\"test_accuracy_comparison{suffix}\" for suffix in SUFFIXES]\n",
    "\n",
    "note_runs_df[labels].apply(pd.Series.value_counts).reindex(LABELS_THAT_SHOULD_BE).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4be453cb92b24d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:54.474676Z",
     "start_time": "2024-07-17T21:41:54.441276Z"
    }
   },
   "outputs": [],
   "source": [
    "quad_split_df\\\n",
    "    .query(LIMITING_QUERY)\\\n",
    "    [ALL_DISCRETIZED_METRICS].apply(lambda x:x.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9ed68b4a63b4ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:56.018234Z",
     "start_time": "2024-07-17T21:41:54.475447Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "err_vars = quad_split_df.groupby([\"params.complexity_measure\"])[['test_accuracy', 'test_recall', 'test_precision']].var()\n",
    "\n",
    "df_to_plot = quad_split_df.groupby([\"params.complexity_measure\"])[['test_accuracy', 'test_recall', 'test_precision']].mean()\n",
    "\n",
    "df_to_plot.plot(kind='bar', ax=ax, yerr=err_vars)\n",
    "\n",
    "ax.set_ylim(0.5, 1)\n",
    "\n",
    "ax.legend([\"accuracy\", \"precision\", \"recall\"])\n",
    "ax.set_xlabel(\"Complexity measure\")\n",
    "ax.set_ylabel(\"Metric value\")\n",
    "ax.axhline(df_to_plot.test_accuracy.max())\n",
    "# for container in ax.containers:\n",
    "#     ax.bar_label(container)\n",
    "# handles, labels = ax.get_legend_handles_labels()\n",
    "# fig.legend(handles, labels, loc='center right')\n",
    "fig.savefig('../figures/quad/complexity-metric-comparison.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d208c1e796b0b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:56.370440Z",
     "start_time": "2024-07-17T21:41:56.019379Z"
    }
   },
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "err_vars = quad_split_df.groupby([\"params.base_clf\"])[['test_accuracy', 'test_recall', 'test_precision']].var()\n",
    "quad_split_df.groupby([\"params.base_clf\"])[['test_accuracy', 'test_recall', 'test_precision']].mean().plot(kind='bar', ax=ax, yerr=err_vars)\n",
    "\n",
    "ax.set_ylim(0.5, 1)\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Base classifier\")\n",
    "ax.set_ylabel(\"Metric value\")\n",
    "ax.legend([\"accuracy\", \"precision\", \"recall\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10491c1c-3e4a-415f-ab18-7cbfe95a5cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMITING_QUERY = \"`params.min_samples` == '28' and `params.min_split_percentage` == '0.183' and `params.base_clf` == 'dt' and `params.complexity_measure` == 'density'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd4b3dbcdb5a8bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:56.390864Z",
     "start_time": "2024-07-17T21:41:56.371541Z"
    }
   },
   "outputs": [],
   "source": [
    "def vals_to_percentage(l):\n",
    "    total = sum(l)\n",
    "    \n",
    "    return [round(item/total*100,2) for item in l]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fdb22fbd082147",
   "metadata": {},
   "source": [
    "## WINS-LOSSES acc general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86764ece5b36a27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:56.405909Z",
     "start_time": "2024-07-17T21:41:56.391619Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_bar(labels, values_dict, quants, ax):\n",
    "    plot_labels = [l.split('_')[-1].upper() for l in labels]\n",
    "    data = np.array(list(values_dict.values()))\n",
    "    data_cum = data.cumsum(axis=1)\n",
    "        \n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.set_xlim(0, np.sum(data, axis=1).max())\n",
    "\n",
    "    for i, colname in enumerate(quants):\n",
    "        widths = data[:, i]\n",
    "        starts = data_cum[:, i] - widths\n",
    "        rects = ax.barh(plot_labels, widths, left=starts, height=0.5, label=colname)\n",
    "\n",
    "        ax.bar_label(rects, label_type='center')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd21644dd3d312c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T21:41:57.173072Z",
     "start_time": "2024-07-17T21:41:56.406628Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, sharey=True, figsize=(10, 10))\n",
    "\n",
    "\n",
    "ax1.set_title(\"Accuracy\")\n",
    "labels = [f\"test_accuracy_comparison{suffix}\" for suffix in SUFFIXES]\n",
    "vals_to_plot = {k: vals_to_percentage(v.values()) for k,v in quad_split_df.query(LIMITING_QUERY)[labels].apply(pd.Series.value_counts).reindex(LABELS_THAT_SHOULD_BE).to_dict().items()}\n",
    "plot_bar(labels, vals_to_plot, ['better', 'equal', 'worse'], ax1)\n",
    "\n",
    "ax2.set_title(\"Recall\")\n",
    "labels = [f\"test_recall_comparison{suffix}\" for suffix in SUFFIXES]\n",
    "vals_to_plot = {k: vals_to_percentage(v.values()) for k,v in quad_split_df.query(LIMITING_QUERY)[labels].apply(pd.Series.value_counts).reindex(LABELS_THAT_SHOULD_BE).to_dict().items()}\n",
    "plot_bar(labels, vals_to_plot, ['better', 'equal', 'worse'], ax2)\n",
    "\n",
    "\n",
    "ax3.set_title(\"Precision\")\n",
    "labels = [f\"test_precision_comparison{suffix}\" for suffix in SUFFIXES]\n",
    "vals_to_plot = {k: vals_to_percentage(v.values()) for k,v in quad_split_df.query(LIMITING_QUERY)[labels].apply(pd.Series.value_counts).reindex(LABELS_THAT_SHOULD_BE).to_dict().items()}\n",
    "plot_bar(labels, vals_to_plot, ['better', 'equal', 'worse'], ax3)\n",
    "\n",
    "handles, labels = ax2.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='center right')\n",
    "\n",
    "fig.savefig('../figures/quad/overall-performance-barplot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f48fbef6133a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC_LABELS = [f\"test_accuracy_comparison{suffix}\" for suffix in SUFFIXES]\n",
    "PRECISION_LABLES = [f\"test_precision_comparison{suffix}\" for suffix in SUFFIXES]\n",
    "RECALL_LABLES = [f\"test_recall_comparison{suffix}\" for suffix in SUFFIXES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f111f4d7c0e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLEXITIES_TO_CONSIDER = ['f2', 't4', 'c1', 'n3', 'l2', 'density']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7354a3ff722224",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLEXITIES_WITH_HIGHEST_VARIANCE = ['f2', 't4', 'c1', 'n3', 'l2', 'density']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc42e068-1753-4dc8-831b-5da631665e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sure_all_labels_are_there(df):\n",
    "    missing_labels = set(LABELS_THAT_SHOULD_BE) - set(df.index)\n",
    "\n",
    "    for label in missing_labels:\n",
    "        df.loc[label] = pd.Series()\n",
    "\n",
    "    return df.reindex(LABELS_THAT_SHOULD_BE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92115b68-cbcf-4958-a898-569f29e1436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,3, sharey=True, figsize=(20, 10))\n",
    "\n",
    "axes = axes.reshape(-1)\n",
    "\n",
    "axes_iter = iter(axes)\n",
    "plot_labels = [l.split('_')[-1].upper() for l in ACC_LABELS]\n",
    "\n",
    "\n",
    "\n",
    "for labels, label in zip([ACC_LABELS, RECALL_LABLES, PRECISION_LABLES], [\"Accuracy\", \"Recall\", \"Precision\"]):\n",
    "    for value in ['low', 'medium', 'high']:\n",
    "        ax = next(axes_iter)\n",
    "        vals_to_plot = {k: vals_to_percentage(v.values()) for k,v in make_sure_all_labels_are_there(quad_split_df.query(LIMITING_QUERY).query(f\"`overall-complexity` == '{value}'\")[labels].apply(pd.Series.value_counts)).fillna(0).to_dict().items()}\n",
    "    \n",
    "        data = np.array(list(vals_to_plot.values()))\n",
    "        data_cum = data.cumsum(axis=1)\n",
    "        ax.invert_yaxis()\n",
    "        ax.xaxis.set_visible(False)\n",
    "        # ax.yaxis.set_visible(False)\n",
    "        ax.set_xlim(0, np.sum(data, axis=1).max())\n",
    "\n",
    "        for i, colname in enumerate(['better', 'equal', 'worse']):\n",
    "            widths = data[:, i]\n",
    "            starts = data_cum[:, i] - widths\n",
    "            rects = ax.barh(plot_labels, widths, left=starts, height=0.5, label=colname)\n",
    "            ax.bar_label(rects, label_type='center')\n",
    "    \n",
    "        ax.set_title(f\"complexity {value} {label}\")\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='center right')\n",
    "fig.savefig(\"../figures/quad/overall-complexity-barplot.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d5bd0b5c910a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, sharey=True, figsize=(20, 5))\n",
    "\n",
    "axes = axes.reshape(-1)\n",
    "\n",
    "axes_iter = iter(axes)\n",
    "plot_labels = [l.split('_')[-1].upper() for l in ACC_LABELS]\n",
    "\n",
    "\n",
    "for value in ['low', 'medium', 'high']:\n",
    "\n",
    "    ax = next(axes_iter)\n",
    "    vals_to_plot = {k:  vals_to_percentage(v.values()) for k,v in quad_split_df.query(LIMITING_QUERY).query(f\"`overall-complexity` == '{value}'\")[ACC_LABELS].apply(pd.Series.value_counts).reindex(LABELS_THAT_SHOULD_BE).fillna(0).to_dict().items()}\n",
    "\n",
    "    data = np.array(list(vals_to_plot.values()))\n",
    "    data_cum = data.cumsum(axis=1)\n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.set_visible(False)\n",
    "    # ax.yaxis.set_visible(False)\n",
    "    ax.set_xlim(0, np.sum(data, axis=1).max())\n",
    "\n",
    "    for i, colname in enumerate(['better', 'equal', 'worse']):\n",
    "        widths = data[:, i]\n",
    "        starts = data_cum[:, i] - widths\n",
    "        rects = ax.barh(plot_labels, widths, left=starts, height=0.5, label=colname)\n",
    "        ax.bar_label(rects, label_type='center')\n",
    "\n",
    "    ax.set_title(f\"complexity {value}\")\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='center right')\n",
    "fig.savefig(\"../figures/quad/accuracy-overall-complexity-barplot.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9440b0626f6f3d6a",
   "metadata": {},
   "source": [
    "## Models complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0902047de8e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_COMPLEXITY_LABELS = ['complexity',\"complexity_rf\", \"complexity_dt\", 'complexity_rulefit', \"complexity_oner\"]\n",
    "MODEL_COMPLEXITY_LABELS_WO_RF = ['complexity', \"complexity_dt\", 'complexity_rulefit', \"complexity_oner\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22981810b888baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_split_df[MODEL_COMPLEXITY_LABELS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c773b72e69d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_split_df.query(LIMITING_QUERY).groupby(\"overall-complexity\")[MODEL_COMPLEXITY_LABELS_WO_RF].mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cff501af0b78f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_split_df.query(LIMITING_QUERY).groupby(\"overall-complexity\")[MODEL_COMPLEXITY_LABELS_WO_RF].var().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0472a2f882584d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = pd.Categorical([ 'low', 'medium', 'high'],ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f527f4c64523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_split_df \\\n",
    "    .query(LIMITING_QUERY) \\\n",
    "    .groupby('overall-complexity')[['complexity_dt', 'complexity']] \\\n",
    "    .mean().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e44c41c143fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(15, 7))\n",
    "\n",
    "quad_split_df\\\n",
    "    .query(LIMITING_QUERY) \\\n",
    "    [['test_accuracy_better_rf'] + ALL_DISCRETIZED_METRICS] \\\n",
    "    .melt('test_accuracy_better_rf')\\\n",
    "    .groupby(['variable', 'value'], as_index=False)['test_accuracy_better_rf'].var()\\\n",
    "    .groupby('variable')['test_accuracy_better_rf'].var()\\\n",
    "    .rename(index=lambda name: name.split('-')[0]).plot(kind='pie', ax=ax1)\n",
    "\n",
    "ax1.set_title(\"Variance of wins against Random Forest\")\n",
    "\n",
    "quad_split_df\\\n",
    "    .query(LIMITING_QUERY) \\\n",
    "    [['test_accuracy_better_dt'] + ALL_DISCRETIZED_METRICS] \\\n",
    "    .melt('test_accuracy_better_dt')\\\n",
    "    .groupby(['variable', 'value'], as_index=False).apply(lambda x: np.sum(x)/len(x))\\\n",
    "    .groupby('variable')['test_accuracy_better_dt'].var()\\\n",
    "    .rename(index=lambda name: name.split('-')[0]).plot(kind='pie', ax=ax2)\n",
    "\n",
    "ax2.set_title(\"Variance of wins against Decision Tree\")\n",
    "fig.savefig('../figures/quad/variance-of-wins.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccaff8f-b605-4e49-98d1-e6c3ecde73da",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_variance_metrics = quad_split_df\\\n",
    "    .query(LIMITING_QUERY) \\\n",
    "    [['test_accuracy_better_dt'] + ALL_DISCRETIZED_METRICS] \\\n",
    "    .melt('test_accuracy_better_dt')\\\n",
    "    .groupby(['variable', 'value'], as_index=False).apply(lambda x: np.sum(x)/len(x))\\\n",
    "    .groupby('variable')['test_accuracy_better_dt'].var().sort_values(ascending=False)[:5].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3b534f-50ee-4f12-b7e5-dfdb45fa464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_variance_metrics = set(most_variance_metrics).union(quad_split_df\\\n",
    "    .query(LIMITING_QUERY) \\\n",
    "    [['test_accuracy_better_rf'] + ALL_DISCRETIZED_METRICS] \\\n",
    "    .melt('test_accuracy_better_rf')\\\n",
    "    .groupby(['variable', 'value'], as_index=False).apply(lambda x: np.sum(x)/len(x))\\\n",
    "    .groupby('variable')['test_accuracy_better_rf'].var().sort_values(ascending=False)[:4].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08826d0-3a99-4d7d-a66c-b13993c79198",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLEXITIES_TO_CONSIDER = [m.split(\"-\")[0]  for m in most_variance_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b49169d-298a-4eb3-93ff-2c61250e618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLEXITIES_TO_CONSIDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970e00c-61f8-457b-82cc-c69b724ad6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(COMPLEXITIES_TO_CONSIDER),3,figsize=(20, 20), sharey='row')\n",
    "\n",
    "axes = axes.reshape(-1)\n",
    "\n",
    "axes_iter = iter(axes)\n",
    "for complexity in COMPLEXITIES_TO_CONSIDER:\n",
    "    plot_labels = [l.split('_')[-1].upper() for l in ACC_LABELS]\n",
    "    \n",
    "    \n",
    "    for value in ['low', 'medium', 'high']:\n",
    "\n",
    "        ax = next(axes_iter)\n",
    "        vals_to_plot = {k:  vals_to_percentage(v.values()) for k,v in quad_split_df.query(LIMITING_QUERY).query('`params.base_clf` == \"dt\"').query(f\"`{complexity}-discretized` == '{value}'\")[ACC_LABELS].apply(pd.Series.value_counts).reindex(LABELS_THAT_SHOULD_BE).fillna(0).to_dict().items()}\n",
    "\n",
    "        data = np.array(list(vals_to_plot.values()))\n",
    "        data_cum = data.cumsum(axis=1)\n",
    "        ax.invert_yaxis()\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.set_xlim(0, np.sum(data, axis=1).max())\n",
    "    \n",
    "        for i, colname in enumerate(['better', 'equal', 'worse']):\n",
    "            widths = data[:, i]\n",
    "            starts = data_cum[:, i] - widths\n",
    "            rects = ax.barh(plot_labels, widths, left=starts, height=0.5, label=colname)\n",
    "            ax.bar_label(rects, label_type='center')\n",
    "    \n",
    "        ax.set_title(f\"{complexity}-{value}\")\n",
    "\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='center right')\n",
    "fig.savefig('../figures/quad/accuracy-with-variance-complexity-metrics-barplot.pdf')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
